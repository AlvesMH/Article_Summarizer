services:
  - type: web
    name: sea-lion-app
    env: python
    plan: free
    rootDir: .
    buildCommand: |
      # 1) Build frontend
      cd frontend
      npm ci || npm install
      # same-origin API, no base needed:
      # VITE_API_BASE_URL left empty so fetch('/api/...') works
      npm run build

      # 2) Install backend deps
      cd ..
      pip install -r backend/requirements.txt

      # 3) Place the built frontend where FastAPI can serve it
      rm -rf backend/frontend_dist
      mkdir -p backend/frontend_dist
      cp -r frontend/dist/* backend/frontend_dist/
    startCommand: uvicorn app.main:app --app-dir backend --host 0.0.0.0 --port $PORT
    envVars:
      - key: SEA_LION_API_KEY
        sync: false
      - key: HUGGINGFACE_API_TOKEN
        sync: false
      - key: CHROMA_DB_DIR
        value: /data/chroma_lessons
      - key: SEA_LION_BASE_URL
        value: https://api.sea-lion.ai/v1/chat/completions
      - key: DEFAULT_SEALION_MODEL
        value: aisingapore/Gemma-SEA-LION-v3-9B-IT
      - key: HF_EMBED_MODEL
        value: sentence-transformers/all-MiniLM-L6-v2
      - key: HF_EMBED_API
        value: https://router.huggingface.co/hf-inference/models/sentence-transformers/all-MiniLM-L6-v2/pipeline/feature-extraction
    disk:
      name: chroma-disk
      mountPath: /data
      

